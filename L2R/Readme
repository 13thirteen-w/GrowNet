######## ReadMe file for GrowNet on Learning to Rank ########

########## General Info: ##############

1. All L2R related codes are in L2R file : GrowNet/L2R/

2. All L2R data is located in this links: ## TODO add links to Yahoo and MSLR data. You can add .pkl files if the size id small.

# dataset                # Number of features

Microsoft (MSLR WEB-10K)       136
Yahoo                          518

3. Data loading and creating dataloader are handled in GrowNet/L2R/data/data.py

4. Individual model class and ensemble architecture are in GrowNet/L2R/models:  mlp.py and dynamic_net.py. 
You can increase number of hidden layers or change activation function from here: mlp.py

5. All results together with hyper parameters are stored in GrowNet/L2R/results folder in .npz file.

6. In each stage Boosting Net is saved to GrowNet/L2R/ckpt. 

7. GrowNet/L2R/main_reg_cv.py is the main script for regression task where the number of models are selected based on CV (5-10% of the training data)
are reserved for validation and tested on the Test data. You may change the normalization technique or optimizer from here

8. GrowNet Backup/Regression/train_reg.sh is the shell script that runs the code where you can also play around hyperparameters of the Boosting Net:
Parameters: (Sample example)

data = microsoft  				       	       --> name of the dataset

CUDA_VISIBLE_DEVICES=1 python main_l2r_pairwise_cv.py \        --> main python script to run. You may run main_reg.py but get rid of --cv parameter.
    --feat_d 136 \                                             --> Int: # of features in the data: shell script itself has the numbers commented in
    --hidden_d 128 \                                           --> Int: # of units in the hidden layer
    --boost_rate 1 \					       --> Float: Boost rate to weight the model outputs for final output
    --lr 0.005 \					       --> Float: Learning rate	
    --L2 .0e-3 \					       --> Float: L2 regularization rate (weight decay)	
    --num_nets 40 \					       --> Int: Max number of models in the net	 
    --data ${data} \					       --> Assigning data from above	
    --tr /datapath/${data}_tr.npz \    			       --> Path to the training data 
    --te /datapath/${data}_te.npz \    			       --> Path to the test data
    --batch_size 10000 \				       --> Int: Training batch size	
    --epochs_per_stage 1 \				       --> Int: Number of epochs for training each model: generally set to 1 sometimes 2
    --correct_epoch 1 \					       --> Int: Number of epochs for the Corrective step: generally set to 1 or 2
    --normalization True \				       --> Boolean: Normalization, in regression, standardization to apply or Not
    --cv True \						       --> Boolean: Performing CV to select number of models in the Boosting, reserving 5-10% of the training data. You can change the percentage inside of main script: get_data()
    --out_f ./ckpt/${data}_reg.pth \			       --> Saving the model in each stage (new model added) to this file 
    --cuda 						       --> Cuda option: On our case it is ON



########## How top Run the Code ##############

1. Change your directory to GrowNet/L2R/

2. Open train_l2r.sh shell script (vim train_l2r.sh) and follow these steps:
	
	a. Choose the data name you want to try: data = microsoft . The default Fold is set to 1. You can change the 
	   the Fold number inside of main script.
	
	b. Change --feat_d into the number of features the dataset has: in the case of slice_localization  136
	
	c. You may want to adjust the number of units in hidden layer based on the dataset: I generally choose 
	   the hidden_d something between  feat_d/2 and 2*feat_d
	   If the hidden_d is very big then models overfits otherwise if very small can't learn.

	d. If you want to try  new L2R data then be sure you put it into .npz format with the name analogous to --tr and --te. 
	   For now please also add the data name into manuscript in the get_data() function.

	e. The rest is optional: you may or may not change 

3. To enforce the changes you have done run this line on command line: chmod +x train_l2r.sh

4. Finally run the script by executing this line on command window: ./train_l2r.sh 
   This should render the Microsoft data results.


